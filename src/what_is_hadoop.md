# Вступ до Apache Hadoop

## Що таке Apache Hadoop?

**Apache Hadoop** — це відкрита платформа для розподіленої обробки та зберігання великих обсягів даних. Розроблена спільнотою Apache, Hadoop дозволяє використовувати звичайне апаратне забезпечення для розподіленої обробки даних. Вона особливо підходить для виконання завдань аналізу великих даних (Big Data).

### Основні характеристики Apache Hadoop

1. **Масштабованість**: Hadoop здатен обробляти великі обсяги даних шляхом розподілу навантаження між сотнями або навіть тисячами серверів. Це дозволяє організаціям обробляти петабайти даних, збільшуючи кількість вузлів у кластері без значних змін у налаштуваннях.

2. **Толерантність до відмов**: Hadoop автоматично створює резервні копії даних між різними вузлами в кластері. У випадку збою одного або кількох вузлів, система може продовжувати роботу, не втрачаючи даних та не перериваючи процес обробки.

3. **Економічність**: Платформа використовує звичайне недороге апаратне забезпечення (commodity hardware) та програмне забезпечення з відкритим кодом, що дозволяє знизити витрати на інфраструктуру.

4. **Розширюваність**: Hadoop складається з модулів, які можна комбінувати для створення розширюваних систем, що відповідають конкретним вимогам до обробки даних.

### Компоненти Apache Hadoop

Apache Hadoop складається з декількох основних компонентів:

- **Hadoop Distributed File System (HDFS)**: це файлова система, що дозволяє зберігати дані розподілено між вузлами в кластері.
  
- **MapReduce**: це модель програмування, яка дозволяє виконувати паралельні обчислення над великими масивами даних.
  
- **YARN**: платформа управління ресурсами в Hadoop, яка забезпечує розподіл ресурсів та керування задачами в кластері.

- **Hadoop Common**: це набір допоміжних інструментів і бібліотек, які підтримують інші модулі Hadoop.

### Застосування Apache Hadoop

Apache Hadoop широко використовується в різних сферах:

- **Аналіз великих обсягів даних**: обробка структурованих та неструктурованих даних для отримання корисної інформації.
- **Система рекомендацій**: створення персоналізованих рекомендацій для користувачів на основі історії їхньої поведінки.
- **Обробка журналів активності**: аналіз даних журналів для виявлення проблем та оптимізації систем.


Apache Hadoop є потужною платформою для розподіленої обробки великих обсягів даних. Вона поєднує в собі масштабованість, толерантність до відмов, економічність і розширюваність, що робить її ідеальним вибором для багатьох сучасних завдань у сфері великих даних.


